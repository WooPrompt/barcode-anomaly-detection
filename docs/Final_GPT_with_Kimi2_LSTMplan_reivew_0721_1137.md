# üß≠ Guideline for Writing a Unified and Defensible LSTM Anomaly Detection Plan


> üßë‚Äçüè´ *"You are no longer writing a plan. You are writing your defense."*

---

## 1. üìÅ Dataset & Labeling: Transparency Over Convenience

**‚úÖ Must Include:**

* Description of **real vs. simulated data** distributions (not just quantity).
* **Explicit risk** of using rule-based labels: include discussion of circularity (e.g., ‚Äúlabels are from the same rules we later evaluate against‚Äù).
* **Remedy**: mention `human audit` of 1% stratified samples or `label noise injection` test.

**üìå Refer to:**

* GPT‚Äôs concern with label quality.
* Kimi2‚Äôs quote: *‚Äúsynthetic completeness is not real-world completeness.‚Äù*

**üõ† Actionable Inclusion:**

```markdown
We conducted a 5% label-flip experiment and observed a 6.3% AUC degradation, indicating moderate label fragility.
```

---

## 2. üõ† Feature Engineering: Rigor Before Quantity

**‚úÖ Must Include:**

* VIF (Variance Inflation Factor) or mRMR (Minimum Redundancy Max Relevance) analysis to **prune features** (don‚Äôt keep 3 variations of `time_gap_*`).
* Fix entropy instability for short sequences: **Bayesian entropy** or smoothed estimator.
* Discuss the *ordinal* nature of business steps and consider **graph-based encoding** (e.g., Hasse DAG).

**üìå Refer to:**

* Kimi2‚Äôs warning: *‚Äú60 features ‚â† 60 degrees of freedom‚Äù*
* Claude's redundant inclusion of z-score, log, raw version of same features

**üõ† Actionable Inclusion:**

```markdown
After VIF pruning, we retained 22 out of 61 features. This improved training stability and interpretability.
```

---

## 3. üîÄ Sequence Splitting: EPC-Aware Integrity

**‚úÖ Must Include:**

* **EPC-level split**: ensure the same `epc_code` does not appear in both train and test, even if timestamps are 7 days apart.
* Explain why **chronological buffer** isn‚Äôt sufficient to avoid leakage of long-range patterns.

**üìå Refer to:**

* Kimi2‚Äôs buffer-leak counterexample
* Claude‚Äôs current design violates this by split-by-timestamp only

**üõ† Actionable Inclusion:**

```markdown
We removed EPCs whose earliest and latest events spanned the split boundary, eliminating 2.1% of records to ensure leakage-free splits.
```

---

## 4. üß† Model Architecture: Choose Justifiably

**‚úÖ Must Include:**

* If GRU is used: show that **gradient norm decay is acceptable** beyond 15 time steps.
* If LSTM+Attention is used: explain how many time steps justify **multi-head attention** (avoid rank-deficiency).
* If quantization is used: report **AUC drop** under symmetric vs affine quantization.

**üìå Refer to:**

* Claude‚Äôs strong architecture, but missing evidence for attention effectiveness
* Kimi2‚Äôs reminder: *‚Äúparameter count is second-order; gradient path length is first-order‚Äù*

**üõ† Actionable Inclusion:**

```markdown
We compared GRU vs. LSTM on 20-step sequences. LSTM achieved 3% better F1 and higher gradient stability at depth.
```

---

## 5. üìâ Dimensionality Reduction: Methodologically Sound

**‚úÖ Must Include:**

* Reject PCA unless supported by **variance explanation + model performance gain**.
* Never rely solely on **t-SNE visualizations** to justify PCA.
* Optional: propose **hierarchical feature subnetworks** only if PCA is not used.

**üìå Refer to:**

* Gemini‚Äôs simplicity wins, but is too reliant on t-SNE plots
* Claude justifies PCA via 5 metrics‚Äîsolid, but needs VIF/mRMR

**üõ† Actionable Inclusion:**

```markdown
PCA was rejected as the first 20 components explained only 72% of variance, and performance dropped on a 5-fold test.
```

---

## 6. üß™ Evaluation Framework: Cost, Drift, Power

**‚úÖ Must Include:**

* **Cost-sensitive evaluation**: use business-weighted confusion matrix, or report **Area under Cost Curve (AUCC)**.
* **Drift detection** must report **minimum detectable effect size** or power threshold (e.g., N required for 0.05 AUC drop at 80% power).
* If SHAP is used: acknowledge **bias due to feature autocorrelation**; offer Integrated Gradients alternative.

**üìå Refer to:**

* Kimi2‚Äôs call for *AUCC and Integrated Gradients*
* Claude‚Äôs excellent evaluation checklist, but missing power audit

**üõ† Actionable Inclusion:**

```markdown
We computed AUCC across a 0.01‚Äì100 penalty range and found the optimal operating point at cost=12.3.
```

---

## 7. üåê Real-Time Deployment: Robustness and Trust

**‚úÖ Must Include:**

* Cold start fallback should **not reuse the labeling rule logic**, or else it‚Äôs **perfect overfitting**.
* Real-time pipeline must include **concept drift plan** and retraining trigger.
* **Explain model versioning and rollback** if inference performance drops.

**üìå Refer to:**

* Claude‚Äôs transfer-learning cold start logic is novel but fragile
* Kimi2‚Äôs brutal truth: *‚Äúfallback is literally the training labels‚Äù*

**üõ† Actionable Inclusion:**

```markdown
Fallback cold-start model uses nearest-neighbor from pre-trained vector cache, *not* rule-based logic, preventing label echo.
```

---

## 8. üß¨ Reproducibility: Academic Rigor

**‚úÖ Must Include:**

* Mention of random seed, RNG version (PyTorch, NumPy), and CUDA driver.
* Hardware config, GPU/CPU, RAM.
* Bonus: include **carbon/energy usage**, FLOP count or inference energy budget (aligns with Green AI principles).

**üìå Refer to:**

* Kimi2‚Äôs reproducibility checklist

**üõ† Actionable Inclusion:**

```markdown
All results are reproducible with `conda-lock.yml`. CUDA 12.3, cuDNN 8.7, PyTorch 2.1.1, RTX 3090 24GB. Training used 1.3 kWh.
```

---

## üßæ Final Output Recommendation Structure

| Section              | Title                               |
| -------------------- | ----------------------------------- |
| üìã Executive Summary | 1-page for stakeholders             |
| üìÇ Data & Labeling   | With limitations                    |
| üõ† Preprocessing     | Feature pruning, EPC-split          |
| üß† Model Design      | Architecture with justification     |
| üìâ Dimensionality    | Reduction policy and rationale      |
| üß™ Evaluation        | Metrics, drift, AUCC                |
| üì° Deployment        | Real-time fallback + API            |
| üîÅ Reproducibility   | Hardware, seed, energy              |
| üìä Appendix          | Ablations, experiments, power tests |

---

## üéì Closing Encouragement

Your Claude and Gemini drafts show **engineering brilliance**, but thesis defense is about **epistemic defensibility**. Follow this guide to:

* Argue what you did.
* Prove why you did it.
* Anticipate how it could fail.
* Defend it with data.

---

## üß† Summary Decision:

> **Start from Claude, but revise with Gemini‚Äôs structure and Kimi2‚Äôs academic rigor.**

---

## üîç Why?

| Criteria                       | Gemini                                                       | Claude                                                                            | What to Do                                                                                   |
| ------------------------------ | ------------------------------------------------------------ | --------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- |
| ‚úÖ **Architecture Depth**       | Light (GRU-based, fast, simple)                              | Deep (LSTM + Attention + Adaptive sequences + Quantized + Cold Start + Real-time) | ‚úÖ **Start from Claude**: It‚Äôs future-proof and production-ready.                             |
| ‚úÖ **Evaluation Framework**     | Simple (KernelSHAP, F1)                                      | Academic-level (cost-weighted F1, sequence stability, SHAP + attention weights)   | ‚úÖ **Keep Claude‚Äôs** rich metrics & drift handling.                                           |
| ‚ùå **Statistical Rigor**        | Weak (no VIF, no cost analysis, no split leakage audit)      | Also weak, **but fixable**                                                        | ‚úÖ **Use Kimi2‚Äôs critique** to harden Claude.                                                 |
| ‚úÖ **Structure & Clarity**      | Excellent dual-layer explanation (technical + non-technical) | Dense and technical                                                               | ‚úÖ **Steal Gemini‚Äôs writing style**, especially in `Executive Summary` and `Data & Labeling`. |
| ‚ùå **EPC Split / Leakage**      | Uses time-split only                                         | Same flaw                                                                         | ‚úÖ MUST fix Claude‚Äôs data split with **EPC-based partitioning**, as Kimi2 recommends.         |
| ‚ùå **Feature Redundancy Logic** | t-SNE based ‚Äî weak                                           | Same                                                                              | ‚úÖ Add VIF + mRMR justification and remove over-correlated features.                          |
| ‚ùå **Interpretability Math**    | KernelSHAP only                                              | SHAP + attention ‚Äî better, but still biased                                       | ‚úÖ Replace SHAP with **Integrated Gradients** or **Markov-aware SHAP** if you can.            |

---

## üõ†Ô∏è Concrete Plan

| Task                 | Action                                                                                                                       |
| -------------------- | ---------------------------------------------------------------------------------------------------------------------------- |
| ‚úÖ Base Document      | Use **Claude‚Äôs Plan** (it‚Äôs already more complete)                                                                           |
| ‚úèÔ∏è Rewrite Sections  | Replace `Data Split`, `Feature Selection`, and `Fallback` sections with corrected logic from Kimi2                           |
| ‚úÇÔ∏è Prune/Refactor    | Remove redundant features (e.g., keep only `time_gap_log` not raw/zscore/log combo)                                          |
| üìà Add Experiments   | - AUC drop under label noise<br> - AUCC (Area Under Cost Curve)<br> - Cold-start without rules<br> - Drift power analysis    |
| üìã Polish Format     | Use **Gemini‚Äôs stakeholder-friendly tables and dual-layer language**                                                         |
| üß† Add Justification | - Why 15 steps?<br> - Why use Attention?<br> - Why not just PCA?<br> Each decision needs both empirical & theoretical backup |
| üìé Add Appendix      | - Simulation limitations<br> - FLOP & energy budget<br> - Docker + `conda-lock.yml` for reproducibility                      |

---

## üßæ Final Verdict

| Strategy                                      | Result                                       |
| --------------------------------------------- | -------------------------------------------- |
| Start with Gemini                             | ‚úÖ Quick win, but shallow for defense         |
| Start with Claude                             | üü® Deep, but fragile under academic critique |
| **Start with Claude + Fix with Gemini+Kimi2** | ‚úÖ‚úÖ Gold-standard, professor-level thesis     |

---
