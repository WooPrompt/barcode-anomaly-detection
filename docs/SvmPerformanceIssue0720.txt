===============================
SVM Performance Debugging Report
===============================

[ROLE]
- Data Analyst
- NLP Researcher
- Data Scientist

[TOPIC]
- Debugging the performance gap between Rule-based (48%) and SVM (0%) anomaly detection systems

------------------------------------------------------------
[QUESTIONS & ANSWERS]
------------------------------------------------------------

[Data & Labeling Issues]

Q1. Are you using the same evaluation dataset for both rule-based (48%) and SVM (0%) metrics?
A1. ‚úÖ Yes - 'tt.txt' compliant split implemented in _split_csv_data_for_evaluation() at svm_csv_trainer.py:378

Q2. How were the labels generated for SVM training? Derived from rule-based outputs or ground truth?
A2. ‚úÖ Rule-based labels via RuleBasedLabelGenerator using multi_anomaly_detector scoring functions

Q3. Can you provide a confusion matrix and classification report for the SVM model?
A3. ‚ùå All metrics are 0 - svm_evaluation_results.json shows 0% precision, recall, F1, and accuracy.
    "support": 0 ‚Äî no samples processed

[Feature Engineering & Data Pipeline]

Q4. What features are being fed into the SVM model?
A4. ‚ö†Ô∏è Potential field mapping failure
    - 15D location features depend on reader_location field
    - Mapping may fail, resulting in empty feature vectors

Q5. Walk me through your data preprocessing pipeline.
A5. ‚ö†Ô∏è Complex pipeline with potential error points:
    - SVMPreprocessingPipeline ‚Üí feature_extractors ‚Üí label_generators
    - Multiple transformation layers introduce failure risk

Q6. Are there any data leakage issues?
A6. ‚úÖ No leakage ‚Äî proper chronological split confirmed

[Model Implementation & Validation]

Q7. What are your SVM hyperparameter settings?
A7. ‚ö†Ô∏è Minimal config used:
    svm_params = {'kernel': 'rbf', 'gamma': 'scale', 'nu': 0.1}
    No hyperparameter tuning evident

Q8. Are you handling class imbalance properly?
A8. ‚ùå No explicit handling ‚Äî OneClassSVM used without SMOTE or class weighting

Q9. Can you show examples where rule-based catches anomalies but SVM fails?
A9. ‚ùå Not possible ‚Äî SVM makes no predictions due to JSON serialization error

[Technical Validation]

Q10. Is the SVM model actually training?
A10. ‚ö†Ô∏è Signs of failure ‚Äî JSON serialization error during prediction suggests pipeline breakdown

------------------------------------------------------------
[SVM Bug-Fix Debugging Script ‚Äì Plain-Text Checklist]
------------------------------------------------------------

Each debugging question is followed by the validation snippet, expected outcome, and current status.

1. Are all reader_location values correctly populated after merge?
   Validation: assert df['reader_location'].notna().all()
   Expected: True
   Status: ‚ùå INCONSISTENT ‚Äì mapping sometimes fails.

2. Does the rule-based detector actually return any anomalies for the evaluation split?
   Validation: rule_df[rule_df['label'] == 1].head(20)
   Expected: non-empty DataFrame
   Status: ‚úÖ YES ‚Äì anomalies exist (rule-based 56.6 %).

3. Are the One-Class SVM labels only 0 (normal) during training?
   Validation: np.unique(y_train)
   Expected: [0]
   Status: ‚ùå NOT VERIFIED ‚Äì rule-based noise may creep in.

4. Do the 15-D location features ever produce an all-zero vector?
   Validation: (features == 0).all(axis=1).sum()
   Expected: 0
   Status: ‚ùå SUSPECTED ‚Äì silent failure possible.

5. Is reader_location always present in the row dict passed to feature extractors?
   Validation: assert 'reader_location' in row.keys()
   Expected: True
   Status: ‚ùå INCONSISTENT ‚Äì missing field in some rows.

6. Are statistical jump features identical for >90 % of EPC sequences?
   Validation: features.nunique() / len(features) < 0.1
   Expected: False
   Status: ‚ùå AGGREGATION COLLAPSE suspected.

7. t-SNE plot of 1000 feature vectors ‚Äì any separation?
   Validation: TSNE(n_components=2).fit_transform(X) ‚Üí visualize
   Expected: visible separation
   Status: ‚ùå NOT YET RUN ‚Äì clusters likely overlap.

8. Median cosine similarity of 50 normal vectors < 0.95?
   Validation: np.median(cosine_similarity(X_norm)) < 0.95
   Expected: True
   Status: ‚ùå HIGH SIMILARITY suspected.

9. Are StandardScaler statistics NaN in any dimension?
   Validation: np.isnan(scaler.mean_).any()
   Expected: False
   Status: ‚ùå LIKELY ‚Äì zero-variance features.

10. Grid-search nu / gamma ‚Äì any combo > 0 %?
    Validation: GridSearchCV(...).best_score_ > 0
    Expected: True
    Status: ‚ùå NOT YET RUN ‚Äì default only.

11. Binary SVC cross-validation ‚Äì F1 > 0 %?
    Validation: cross_val_score(SVC(), X, y, scoring='f1').mean() > 0
    Expected: True
    Status: ‚ùå NOT YET TRIED.

12. Train on 100 EPC sequences ‚Äì still predicts all normal?
    Validation: (model.predict(X_small) == 1).mean() > 0
    Expected: True
    Status: ‚ùå PATHOLOGICAL under-fit.

13. Evaluate with synthetic anomalies ‚Äì still 0 %?
    Validation: accuracy_score(y_true, y_pred) > 0
    Expected: True
    Status: ‚ùå NOT YET TESTED.

14. Exact JSON serialization TypeError message?
    Validation: json.dumps(pred_dict, ensure_ascii=False, default=int)
    Expected: no TypeError
    Status: ‚úÖ CONFIRMED ‚Äì int64 TypeError in logs.

15. Raw SVM decision scores all positive?
    Validation: (model.decision_function(X50) < 0).any()
    Expected: True
    Status: ‚úÖ YES ‚Äì all positive, no anomalies.

16. event_time parsing fails silently?
    Validation: assert not (features == 0).all()
    Expected: True
    Status: ‚ùå POSSIBLE ‚Äì needs probe.

17. Duplicate EPC codes in eval split?
    Validation: df['epc_code'].duplicated().sum() == 0
    Expected: True
    Status: ‚ùå NOT VERIFIED.

18. Zero-length EPC sequences (1 event) causing div-by-zero?
    Validation: assert (epc_group.shape[0] > 1 for _, epc_group in df.groupby('epc_code'))
    Expected: True
    Status: ‚ùå NOT VERIFIED.

19. First failing assertion in pipeline?
    Validation: assert df['reader_location'].notna().all()
    Expected: pass
    Status: ‚ùå FAILS ‚Äì first failure point.

20. Identical feature-vector hashes?
    Validation: len(set(pd.util.hash_pandas_object(features))) > 1
    Expected: True
    Status: ‚ùå NOT YET TESTED.

------------------------------------------------------------
[CRITICAL ISSUES FOUND IN CODE]
------------------------------------------------------------

1. ‚ùó JSON Serialization Bug
   - File: svm_anomaly_detector.py:7
   - Error: "Object of type int64 is not JSON serializable"
   - Cause: Using numpy.int64 instead of Python int
   - Effect: SVM predictions fail, no output returned

2. ‚ùó Field Mapping Inconsistency
   - Files: svm_csv_trainer.py:177-178, loc_err_features.py:62
   - CSV maps location_id ‚Üí reader_location
     ‚Üí df['reader_location'] = df['location_id'].astype(str)
   - Feature extractor assumes reader_location already exists
     ‚Üí row['reader_location']
   - Effect: Feature extraction may break due to missing field

3. ‚ùó Evaluation Results All Zero
   - File: svm_evaluation_results.json
   - Metrics: "precision": 0.0, "recall": 0.0, "f1_score": 0.0, "accuracy": 0.0
   - Support: 0 ‚Äî means no samples processed during evaluation

------------------------------------------------------------
[RECOMMENDED FIX PRIORITY]
------------------------------------------------------------

1. üîß Fix JSON serialization ‚Äî convert numpy int64 ‚Üí Python int
2. üîß Ensure consistent field mapping for reader_location
3. üîß Add error handling to feature extraction stages
4. üîß Implement proper hyperparameter tuning (e.g., grid search)
5. üîß Apply class imbalance techniques ‚Äî SMOTE, weighting, etc.

------------------------------------------------------------
[EXPECTED DELIVERABLES]
------------------------------------------------------------

- Code snippets for data preprocessing and feature engineering
- SVM model training logs and evaluation metrics
- Sample prediction comparisons (rule-based vs SVM)
- Data quality report
- Hyperparameter tuning logs
- Full code review report with issue breakdown

===============================
End of Report
===============================
