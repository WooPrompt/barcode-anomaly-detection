

## project_goal
Build a real-time, API-driven anomaly detection system for supply chain barcodes.
Detect forged EPCs, logistical errors, and impossible travel times using both rule-based logic and machine learning.

## Environment
- OS: Windows
- Language: Python
- Framework: FastAPI

### Main Libraries and Versions
- numpy==2.3.0
- pandas==2.3.0
- scikit-learn==1.6.1
- torch==2.7.1+cu118
- torchvision==0.22.1+cu118
- torchaudio==2.7.1+cu118
- matplotlib==3.10.3
- seaborn==0.13.2

### How to Use
- All development and execution are done inside a Conda virtual environment named `ds`.
- Before running any code, activate the environment:conda activate ds


### Notes
- This environment is optimized for data analysis, machine learning, deep learning, visualization, and API development.
- CUDA support is enabled for torch, torchvision, and torchaudio.
- Using a virtual environment (conda/venv) is strongly recommended for package isolation and reproducibility.



## key_files
- /src/barcode/api.py: FastAPI core (entry point for the API).
- /src/barcode/anomaly_detection_v5.py: Monolithic rule-based anomaly detection (API-ready).
- /src/barcode/anomaly_detection_decomposed.py: Individual standalone functions for each anomaly type (COMPLETE - 4/5 functions implemented).
- /src/barcode/anomaly_detection_combined.py: Full pipeline combining rule-based + SVM detection.
- /src/barcode/transition_time_analyzer_v2.py: Analyzes travel-time anomalies ("jump" errors).
- /data/processed/location_id_withGeospatial.csv: Geospatial reference data for locations.
- /data/processed/business_step_transition_avg_v2.csv: Statistical baseline for travel time validation.
- /data/: Contains raw, processed, and external datasets.
- /docs/: Project documentation and research notes.
- requirements.txt: Python package dependencies.

## data_schema
- scan_location (string): Human-readable location where the EPC was scanned (e.g., '화성공장').
- location_id (integer): Numerical ID for each location.
- hub_type (string): Facility type (e.g., 'HWS_Factory', 'SEL_Logi_HUB_Inbound').
- business_step (string): Stage in supply chain (e.g., 'Factory', 'WMS', 'Logistics_HUB', etc.).
- event_type (string): Action that occurred at that location (e.g., 'Aggregation', 'HUB_Outbound').
- epc_code (string): EPC identifier. Composed of:
  - epc_header (string): Always '001'.
  - epc_company (string): 7-digit company code.
  - epc_product (string): 7-digit product code.
  - epc_lot (string): 6-digit lot code.
  - epc_manufacture (string): 8-digit manufacture date (YYYYMMDD).
  - epc_serial (string): 9-digit unique serial.
- product_name (string): Human-readable product name.
- event_time (datetime): When the scan happened.
- manufacture_date (datetime): Product manufacture timestamp.
- expiry_date (datetime): Product expiry timestamp.
- factory (string): Factory of origin (e.g., 'hws', 'icn').

## anomaly_types
- epcFake: Malformed EPC code (structure-level error).
- epcDup: Same EPC scanned at different locations at the exact same time.
- locErr: Invalid location sequence in supply chain (e.g., backward movement).
- evtOrderErr: Events out of logical order within the same location.
- jump: Travel time between two events is statistically impossible.
- svm_outlier: Statistically detected anomaly using One-Class SVM (not caught by rules).

## ai_guidelines
- Versioning: Use new files for major feature versions (e.g., *_v2.py).
- Coding style: Write reproducible and clear code. Focus comments on the "why" not the "what".
- Prefer clear, educational code over short, clever one-liners.
- Always use GPU if helpful (e.g., for ML).
- When AI helps with planning, let it explain multiple code options with pros/cons.
- After finishing a unit of work (function or file), write a test and commit.
- Limit each request to small changes: ideally ≤1 file, ≤2–3 functions, ≤10 lines per function.

## project_status_update
MODULARIZATION COMPLETE (95%): Individual anomaly detection functions successfully implemented in anomaly_detection_decomposed.py. Only missing detect_jump_anomalies() function extraction from v5.
- DONE: detect_epc_fake() - Format validation 
- DONE: detect_epc_dup() - Duplicate detection
- DONE: detect_loc_err() - Location hierarchy validation  
- DONE: detect_evt_order_err() - Event sequence validation
- PENDING: detect_jump_anomalies() - Statistical travel time analysis (needs extraction)

## data_requirements
For rule-based anomaly detection, ALWAYS use these specific data files:
- Geospatial data: data/processed/location_id_withGeospatial.csv
- Travel time baselines: data/processed/business_step_transition_avg_v2.csv
- These contain pre-calculated statistics and geospatial coordinates required for location validation and jump detection.


## file_correction_guideline
- If a path or filename does not exist, try to:
  1. Auto-correct it using project structure (search `src/`, `data/`, etc).
  2. Suggest corrected paths in your response.
  3. Update the .llm.json or .llm.txt and return the corrected version.
- Confirm with the user if any ambiguity exists (e.g., multiple matching files).
