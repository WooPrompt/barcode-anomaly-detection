Do not use Unicode characters in the print statements that cause encoding errors

## project_goal
Build a real-time, API-driven anomaly detection system for supply chain barcodes.
Detect forged EPCs, logistical errors, and impossible travel times using both rule-based logic and machine learning.

**Current Status**: Rule-based system operational. Next phase: Row-level multi-label SVM system.
**Target**: Replace EPC-groupby approach with row-level binary classification for 5 anomaly types.
**Specification**: See docs/ROW_LEVEL_SVM_SYSTEM_SPECIFICATION.txt for complete implementation details.

## Environment
- OS: Windows
- Language: Python
- Framework: FastAPI

### Main Libraries and Versions
- numpy==2.3.0
- pandas==2.3.0
- scikit-learn==1.6.1
- torch==2.7.1+cu118
- torchvision==0.22.1+cu118
- torchaudio==2.7.1+cu118
- matplotlib==3.10.3
- seaborn==0.13.2

### How to Use
- All development and execution are done inside a Conda virtual environment named `ds`.
- Before running any code, activate the environment:conda activate ds


### Notes
- This environment is optimized for data analysis, machine learning, deep learning, visualization, and API development.
- CUDA support is enabled for torch, torchvision, and torchaudio.
- Using a virtual environment (conda/venv) is strongly recommended for package isolation and reproducibility.



## key_files
- fastapi_server.py: Main API server with both rule-based and SVM endpoints (includes /api/manager/export-and-analyze-async/svm).
- src/barcode/multi_anomaly_detector.py: Rule-based multi-anomaly detection logic (lines 740-884).
- src/barcode/svm_anomaly_detector.py: SVM-based detection system with 5 One-Class SVM models.
- src/barcode/svm_csv_trainer.py: Training pipeline for large CSV datasets with memory-efficient processing.
- evaluate_svm_models.py: Academic evaluation script (tt.txt compliant) comparing SVM vs rule-based.
- src/barcode/svm_preprocessing/: Sophisticated SVM preprocessing pipeline with feature extraction and class imbalance handling.
- src/barcode/svm_preprocessing/feature_extractors/jump_features.py: EPC groupby features (sequence-level).
- src/barcode/svm_preprocessing/feature_extractors/jump_features_event_level.py: Event-level features for row-level processing.
- src/barcode/svm_preprocessing/base_preprocessor.py: EPC groupby logic (lines 127-128).
- /data/processed/location_id_withGeospatial.csv: Geospatial reference data for locations.
- /data/processed/business_step_transition_avg_v2.csv: Statistical baseline for travel time validation.
- /data/raw/*.csv: Training data (icn.csv, kum.csv, ygs.csv, hws.csv) for SVM models.
- /data/: Contains raw, processed, and external datasets.
- /docs/: Project documentation and research notes.
- SVM_IMPLEMENTATION_GUIDE.md: Complete SVM system documentation.
- Î∞îÏΩîÎìú_Ïù¥ÏÉÅÌÉêÏßÄ_ÌîÑÎ°úÏ†ùÌä∏_Í∞úÎ∞úÏùºÏßÄ_Ï¢ÖÌï©Î∂ÑÏÑù.md: Complete 10-day development journey analysis.
- row_level_svm_implementation_plan.txt: Future row-level SVM implementation plan.
- requirements.txt: Python package dependencies.

## data_schema
- scan_location (string): Human-readable location where the EPC was scanned (e.g., 'ÌôîÏÑ±Í≥µÏû•').
- location_id (integer): Numerical ID for each location.
- hub_type (string): Facility type (e.g., 'HWS_Factory', 'SEL_Logi_HUB_Inbound').
- business_step (string): Stage in supply chain (e.g., 'Factory', 'WMS', 'Logistics_HUB', etc.).
- event_type (string): Action that occurred at that location (e.g., 'Aggregation', 'HUB_Outbound').
- epc_code (string): EPC identifier. Composed of:
  - epc_header (string): Always '001'.
  - epc_company (string): 7-digit company code.
  - epc_product (string): 7-digit product code.
  - epc_lot (string): 6-digit lot code.
  - epc_manufacture (string): 8-digit manufacture date (YYYYMMDD).
  - epc_serial (string): 9-digit unique serial.
- product_name (string): Human-readable product name.
- event_time (datetime): When the scan happened.
- manufacture_date (datetime): Product manufacture timestamp.
- expiry_date (datetime): Product expiry timestamp.
- factory (string): Factory of origin (e.g., 'hws', 'icn').

## anomaly_types
- epcFake: Malformed EPC code (structure-level error).
- epcDup: Same EPC scanned at different locations at the exact same time.
- locErr: Invalid location sequence in supply chain (e.g., backward movement).
- evtOrderErr: Events out of logical order within the same location.
- jump: Travel time between two events is statistically impossible.
- svm_outlier: Statistically detected anomaly using One-Class SVM (not caught by rules).

## ai_guidelines
- Versioning: Use new files for major feature versions (e.g., *_v2.py).
- Coding style: Write reproducible and clear code. Focus comments on the "why" not the "what".
- Prefer clear, educational code over short, clever one-liners.
- Always use GPU if helpful (e.g., for ML).
- When AI helps with planning, let it explain multiple code options with pros/cons.
- After finishing a unit of work (function or file), write a test and commit.
- Limit each request to small changes: ideally ‚â§1 file, ‚â§2‚Äì3 functions, ‚â§10 lines per function.

## project_status_update
REAL-TIME BARCODE ANOMALY DETECTION SYSTEM OPERATIONAL (2025-07-19):
- ‚úÖ Rule-based detection: FastAPI backend with 5 anomaly types (epcFake, epcDup, locErr, evtOrderErr, jump)
- ‚úÖ SVM-based detection: 5 One-Class SVM models with sophisticated preprocessing pipeline
- ‚úÖ Multi-file processing: Both systems support multiple file_ids in single API request
- ‚úÖ Academic evaluation: tt.txt compliant train/eval data splitting system
- ‚ö†Ô∏è CURRENT CHALLENGE: SVM zero performance issue - EPC groupby approach loses 90% temporal information
- üìã NEXT PHASE: Row-level multi-label SVM implementation to preserve temporal patterns

### API Endpoints:
- POST /api/manager/export-and-analyze-async (rule-based detection) - PRODUCTION READY
- POST /api/manager/export-and-analyze-async/svm (SVM-based detection) - TRAINING REQUIRED

### SVM System Status:
- Training pipeline: ‚úÖ Implemented (python train_svm_models.py)
- Evaluation system: ‚úÖ Implemented (python evaluate_svm_models.py)
- Feature extraction: ‚úÖ Advanced preprocessing with SMOTE, normalization
- Performance issue: ‚ùå 0% metrics due to EPC groupby information loss

## data_requirements
For rule-based anomaly detection, ALWAYS use these specific data files:
- Geospatial data: data/processed/location_id_withGeospatial.csv
- Travel time baselines: data/processed/business_step_transition_avg_v2.csv
- These contain pre-calculated statistics and geospatial coordinates required for location validation and jump detection.

For SVM-based anomaly detection:
- Training data: data/raw/*.csv (icn.csv, kum.csv, ygs.csv, hws.csv)
- ALL 4 CSV files used for training (merged for maximum data, no validation split)
- Memory-efficient CSV processing pipeline handles large datasets
- Academic evaluation requires train/eval split BEFORE training (tt.txt compliance)


## file_correction_guideline
- If a path or filename does not exist, try to:
  1. Auto-correct it using project structure (search `src/`, `data/`, etc).
  2. Suggest corrected paths in your response.
  3. Update the .llm.json or .llm.txt and return the corrected version.
- Confirm with the user if any ambiguity exists (e.g., multiple matching files).
